<!DOCTYPE html>
<head>
    <meta charset="utf-8"/>
    <title>BalaGAN</title>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
          integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <meta content="width=device-width, initial-scale=1" name="viewport"/>
    <link href="min.css" rel="stylesheet" type="text/css"/>
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({google: {families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]}});</script>
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"
            type="text/javascript"></script><![endif]-->
    <script type="text/javascript">!function (o, c) {
        var n = c.documentElement, t = " w-mod-";
        n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
    }(window, document);</script>
    <link href="img/icon.jpg"
          rel="shortcut icon" type="image/x-icon"/>
    <style>
        .wf-loading * {
            opacity: 0;
        }
    </style>

    <script src="https://threejs.org/build/three.js"></script>
    <script src='https://threejs.org/examples/js/controls/OrbitControls.js'></script>
    <script src='https://threejs.org/examples/js/loaders/OBJLoader.js'></script>
    <script src="meshes/mesh.js"></script>
</head>
<body>



<div class="section hero p2m">
    <div class="container-2 p2m_header_v2 w-container"><h1 class="title">BalaGAN</h1>
        <h1 class="subheader">Cross-Modal Image Translation Between Imbalanced Domains</h1>
        <div class="p2m_authors_list_single w-row">
            <div class="w-col w-col-3 w-col-small-4 w-col-tiny-6">
                <a class="authors" href="https://scholar.google.com/citations?user=-SlS0mgAAAAJ&hl=iw" target="_blank">Or Patashnik</a><sup style="color: #120078; font-size:100%">1</sup></div>
            <div class="w-col w-col-3 w-col-small-2 w-col-tiny-6">
                <a class="authors" href="https://scholar.google.com/citations?user=dEGDyVUAAAAJ&hl=en" target="_blank">Dov Danon</a><sup style="color: #120078; font-size:100%">1</sup></div>
            <div class="w-col w-col-3 w-col-small-2 w-col-tiny-6">
                <a class="authors" href="https://www.cs.sfu.ca/~haoz/" target="_blank">Hao Zhang</a><sup style="color: #120078; font-size:100%">2</sup></div>
            <div class="w-col w-col-3 w-col-small-4 w-col-tiny-6">
                <a class="authors" href="https://danielcohenor.com/" target="_blank">Daniel Cohen-Or</a><sup style="color: #120078; font-size:100%">1</sup>
            </div>
        </div>
        <div class="div-block-10">
            <div class="w-col w-col-4 w-col-small-10 w-col-tiny-10 equal_v2" style="color:#120078"><sup>1</sup>Tel Aviv University</div>
	    <div class="w-col w-col-4 w-col-small-10 w-col-tiny-10 equal_v2" style="color:#120078"><sup>2</sup>Simon Fraser University</div>
        </div>

        <div>
            <br>
            <span class="center"><img style="width:85%" src="img/balagan.png"></span>
        </div>

        <!--start links -->
        <div class="p2m_authors_list_single w-row">
            <div class="w-col w-col-6 w-col-small-6 w-col-tiny-6">
                <a class="authors" href="" target="_blank">
                    <a href="https://arxiv.org/abs/2010.02036" target="_blank"><i
                            class="far fa-4x fa-file text-primary mb-3 "></i></a>
                </a></div>

            <div class="w-col w-col-6 w-col-small-6 w-col-tiny-6">
                <a class="authors" href="" target="_blank">
                    <a href="https://github.com/orpatashnik/BalaGAN" target="_blank"><i
                            class="fab fa-4x fa-github text-primary mb-3 "></i></a>
                </a></div>

        </div>


        <div class="div-block-4 w-row">
            <div class="w-col w-col-6 w-col-small-6 w-col-tiny-6">
                <div class="text-block-2"><strong style="color:#120078" class="icon-bold-text">Paper</strong></div>
            </div>
            <div class="w-col w-col-6 w-col-small-6 w-col-tiny-6">
                <div class="text-block-2">
                    <strong style="color:#120078" class="icon-bold-text">Code</strong>
                </div>
            </div>
        </div>
    </div>

    <!--  end links  -->
</div>
</div>

<div class="white_section">
    <div class="w-container"><h2 class="grey-heading">Abstract</h2>
        <p class="paragraph-3 the_text">
	State-of-the-art image translation methods tend to struggle in an imbalanced domain setting, where one image domain lacks richness and diversity. We introduce a new unsupervised translation 		network, BalaGAN, specifically designed to tackle the domain imbalance problem. We leverage the latent modalities of the richer domain to turn the image-to-image translation problem, between two 		imbalanced domains, into a multi-class translation problem, more resembling the style transfer setting. Specifically, we analyze the source domain and learn a decomposition of it into a set of 		latent modes or classes, without any supervision. This leaves us with a multitude of balanced cross-domain translation tasks, between all pairs of classes, including the target domain. During 	inference, the trained network takes as input a source image, as well as a reference style image from one of the modes as a condition, and produces an image which resembles the source on the 		pixel-wise level, but shares the same mode as the reference. We show that employing modalities within the dataset improves the quality of the translated images, and that BalaGAN outperforms strong 		baselines of both unconditioned and style-transfer-based image-to-image translation methods, in terms of image quality and diversity.
        </p>
    </div>
</div>



<div class="section the_section" data-anchor="slide1">
    <div class="w-container"><h2 class="grey-heading">Video</h2>
        <div class="w-embed-youtubevideo stega_movie youtube" id="w-node-e5e45b1d55ac-81500a5f"
             style="padding-top:56.17021276595745%">
            <iframe allow="autoplay; encrypted-media" allowfullscreen="" frameBorder="0"
                    src="https://www.youtube.com/embed/yNBmY5M8GvE?rel=1&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0"
                    style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto"></iframe>
        </div>
    </div>
</div>



</body></html>
